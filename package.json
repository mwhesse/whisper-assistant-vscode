{
  "name": "whisperx-assistant",
  "displayName": "WhisperX Assistant",
  "description": "Leveraging OpenAI's Whisper to transcribe your speech, enhancing your coding efficiency and experience.",
  "version": "1.2.4",
  "publisher": "mwhesse",
  "icon": "images/whisperx-assistant.png",
  "repository": {
    "type": "git",
    "url": "https://github.com/mwhesse/whisperx-assistant-vscode.git"
  },
  "engines": {
    "vscode": "^1.70.0"
  },
  "categories": [
    "Other"
  ],
  "activationEvents": [
    "onStartupFinished",
    "onDidChangeWorkspaceFolders"
  ],
  "main": "./out/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "whisperXAssistant.toggleRecording",
        "title": "Toggle Recording"
      }
    ],
    "keybindings": [
      {
        "command": "whisperXAssistant.toggleRecording",
        "key": "ctrl+m",
        "mac": "cmd+m"
      }
    ],
    "configuration": {
      "type": "object",
      "title": "WhisperX Assistant Settings",
      "properties": {
        "whisperx-assistant.apiProvider": {
          "type": "string",
          "default": "localhost",
          "enum": [
            "localhost",
            "openai",
            "groq"
          ],
          "description": "Select the API provider for transcription"
        },
        "whisperx-assistant.apiKey": {
          "type": "string",
          "default": "localhost-key-must-be-set",
          "description": "API key for the selected provider (must be set for localhost)"
        },
        "whisperx-assistant.customEndpoint": {
          "type": "string",
          "default": "http://localhost:4444",
          "description": "Custom endpoint URL (localhost only)"
        },
        "whisperx-assistant.customRecordingCommand": {
          "type": "string",
          "default": "",
          "description": "Custom recording command (must include $AUDIO_FILE placeholder). Leave empty to use sox (default). Example for macOS: 'ffmpeg -f avfoundation -i :1 -ac 1 -ar 16000 -sample_fmt s16 $AUDIO_FILE'"
        },
        "whisperx-assistant.model": {
          "type": [
            "string",
            "null"
          ],
          "default": null,
          "description": "Specify the Whisper model to use for transcription. Leave as null to use the provider's default model. Examples: 'whisper-1', 'whisper-large-v3-turbo', or any other model supported by your provider."
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run compile",
    "build": "tsc -p ./",
    "watch": "tsc -watch -p ./",
    "pretest": "npm run compile && npm run lint && (rmdir /s /q .vscode-test 2>nul || echo.)",
    "lint": "eslint src --ext ts",
    "test": "node ./out/test/runTest.js",
    "package": "vsce package",
    "publish": "vsce package && vsce publish",
    "clean": "(rmdir /s /q out 2>nul || echo.) && (rmdir /s /q .vscode-test 2>nul || echo.)"
  },
  "devDependencies": {
    "@eslint/js": "^9.33.0",
    "@types/mocha": "^10.0.1",
    "@types/node": "20.x",
    "@types/vscode": "^1.102.0",
    "@typescript-eslint/eslint-plugin": "^8.39.1",
    "@typescript-eslint/parser": "^8.39.1",
    "@vscode/test-electron": "^2.5.2",
    "@vscode/vsce": "^3.6.0",
    "eslint": "^9.33.0",
    "glob": "^11.0.3",
    "mocha": "^11.7.1",
    "openai": "^4.104.0",
    "typescript": "^5.9.2"
  },
  "dependencies": {
    "openai": "^4.104.0"
  }
}
